{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "5bc3a848",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# 🐍 Install helper libs when running on Colab/Binder\n",
    "#!pip install automata-lib pyformlang graphviz\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Set, Tuple, List\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "218bf8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Rule:\n",
    "    lhs: Tuple[str, ...]   # (a,) or (a,b)\n",
    "    rhs: Tuple[str, ...]   # always a single-letter RHS here\n",
    "\n",
    "@dataclass\n",
    "class Grammar:\n",
    "    name: str\n",
    "    alphabet: Set[str]\n",
    "    rules: List[Rule]\n",
    "\n",
    "    # duplicating / non-duplicating letters\n",
    "    @property\n",
    "    def Sigma_d(self) -> Set[str]:\n",
    "        return {r.lhs[0] for r in self.rules if len(r.lhs)==1 and r.rhs==(r.lhs[0], r.lhs[0])}\n",
    "\n",
    "    @property\n",
    "    def Sigma_n(self) -> Set[str]:\n",
    "        return self.alphabet - self.Sigma_d\n",
    "\n",
    "    def binary_rules(self):\n",
    "        return [r for r in self.rules if len(r.lhs)==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "5a25397d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_interface(A: Set[str], B: Set[str], G: Grammar) -> Set[str]:\n",
    "    \"\"\"Return {z | ∃ x∈A, y∈B, xy→z ∈ R}.\"\"\"\n",
    "    out = set()\n",
    "    for rule in G.binary_rules():\n",
    "        x, y = rule.lhs\n",
    "        (z,) = rule.rhs\n",
    "        if x in A and y in B:\n",
    "            out.add(z)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e60385",
   "metadata": {},
   "source": [
    "## Examples  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "2bed6bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "G1 = Grammar(\n",
    "    name='G1',\n",
    "    alphabet={'a','b','c','d','e','f','g'},\n",
    "    rules=[\n",
    "        Rule(('a',), ('a','a')),\n",
    "        Rule(('b',), ('b','b')),\n",
    "        Rule(('c',), ('c','c')),\n",
    "        Rule(('g',), ('g','g')),\n",
    "        Rule(('a','b'), ('c',)),\n",
    "        Rule(('a','b'), ('g',)),\n",
    "        Rule(('c','b'), ('a',)),\n",
    "        Rule(('c','b'), ('d',)),\n",
    "        Rule(('c','a'), ('e',)),\n",
    "        Rule(('e','d'), ('f',)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "G2= Grammar(\n",
    "    name='G2',\n",
    "    alphabet={'a','b','c'},\n",
    "    rules=[\n",
    "        Rule(('a',), ('a','a')),\n",
    "        Rule(('b',), ('b','b')),\n",
    "        Rule(('c',), ('c','c')),\n",
    "        Rule(('a','b'), ('c',)),\n",
    "        Rule(('a','c'), ('b',))\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "d2a76091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "#  Tree nodes  +  next-relation\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "from dataclasses import dataclass, field\n",
    "from typing import List, Dict, Set, Tuple, FrozenSet\n",
    "\n",
    "@dataclass\n",
    "class TreeNode:\n",
    "    id: int\n",
    "    A: FrozenSet[str]\n",
    "    B: FrozenSet[str]\n",
    "    parent: \"TreeNode | None\" = None        # ▼ needed to test right-desc\n",
    "    is_right: bool = False                  # ▼ was this edge a 'right' child?\n",
    "    children: List[\"TreeNode\"] = field(default_factory=list)\n",
    "    next_nodes: Set[\"TreeNode\"] = field(default_factory=set)\n",
    "    back_edge: \"TreeNode | None\" = None\n",
    "\n",
    "    def label(self) -> str:\n",
    "        return f\"({','.join(sorted(self.A))}|{','.join(sorted(self.B))})\"\n",
    "    def __hash__(self): return self.id\n",
    "\n",
    "def is_right_desc(q: TreeNode, r: TreeNode) -> bool:\n",
    "    \"\"\"Return True iff r is in the subtree rooted at q.right_child.\"\"\"\n",
    "    cur = r\n",
    "    while cur.parent is not None:           # climb towards root\n",
    "        if cur.parent is q:\n",
    "            return cur.is_right             # right child of q?\n",
    "        cur = cur.parent\n",
    "    return False\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "#  Up-closure helper   a ↑\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "def upward_closure(letter: str, G: Grammar) -> Set[str]:\n",
    "    \"\"\"Compute a↑ = closure of {letter} under binary rules.\"\"\"\n",
    "    if letter not in G.Sigma_d:\n",
    "        return {letter}\n",
    "\n",
    "    closure = {letter}\n",
    "    changed = True\n",
    "    while changed:\n",
    "        changed = False\n",
    "        for rule in G.binary_rules():\n",
    "            x, y = rule.lhs\n",
    "            (z,) = rule.rhs          # one-letter RHS in this grammar\n",
    "            if x in closure and y in closure and z not in closure:\n",
    "                closure.add(z)\n",
    "                changed = True\n",
    "    return closure\n",
    "\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "#  Main builder\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "def build_tree(\n",
    "    G: Grammar,\n",
    "    s1: str,\n",
    "    s2: str,\n",
    "    interfaces_seed: dict[Tuple[FrozenSet, FrozenSet], set[str]] | None = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build the parsing tree given *existing* interface information.\n",
    "\n",
    "    interfaces_seed  – mapping (A↑,B↑) ➔ already-known I(A,B)\n",
    "                       (may be empty). New basic interfaces are unioned in.\n",
    "    \"\"\"\n",
    "    if interfaces_seed is None:\n",
    "        interfaces_seed = {}\n",
    "\n",
    "    nodes: list[TreeNode] = []\n",
    "    first_occ: dict[tuple[FrozenSet, FrozenSet], TreeNode] = {}\n",
    "    interfaces: dict[tuple[FrozenSet, FrozenSet], set[str]] = deepcopy(interfaces_seed)\n",
    "    duplicates: list[tuple[TreeNode, TreeNode]] = []\n",
    "\n",
    "    nid = 0\n",
    "    def new_node(A: FrozenSet[str], B: FrozenSet[str],\n",
    "                 parent, is_right) -> TreeNode:\n",
    "        nonlocal nid\n",
    "        n = TreeNode(id=nid, A=A, B=B, parent=parent, is_right=is_right)\n",
    "        nid += 1\n",
    "        nodes.append(n)\n",
    "\n",
    "        lbl = (A, B)\n",
    "        # merge basic interface with any seed info\n",
    "        if lbl not in interfaces:\n",
    "            interfaces[lbl] = set()\n",
    "        interfaces[lbl] |= basic_interface(A, B, G)   # union\n",
    "\n",
    "        if lbl not in first_occ:\n",
    "            first_occ[lbl] = n\n",
    "        return n\n",
    "\n",
    "    # root\n",
    "    A0 = frozenset(upward_closure(s1, G))\n",
    "    B0 = frozenset(upward_closure(s2, G))\n",
    "    root = new_node(A0, B0, None, False)\n",
    "\n",
    "    # DFS stack: (node, ancestor-label-set)\n",
    "    stack: List[Tuple[TreeNode, Set[Tuple[FrozenSet, FrozenSet]]]] = [(root, set())]\n",
    "\n",
    "    while stack:\n",
    "        cur, ancestors = stack.pop()\n",
    "        lbl = (cur.A, cur.B)\n",
    "\n",
    "        # --- duplicate label  -----------------------------------------\n",
    "        if lbl in ancestors:\n",
    "            anc = first_occ[lbl]\n",
    "            cur.back_edge = anc\n",
    "            duplicates.append((cur, anc))           # ▼ remember for final pass\n",
    "            continue                                # no children\n",
    "\n",
    "        # --- fresh along this path  -----------------------------------\n",
    "        C = interfaces[lbl]\n",
    "        dup_letters = [c for c in C if c in G.Sigma_d]\n",
    "        new_anc = ancestors | {lbl}\n",
    "\n",
    "        for c in dup_letters:\n",
    "            cup = frozenset(upward_closure(c, G))\n",
    "\n",
    "            left  = new_node(cur.A, cup,  cur, False)\n",
    "            right = new_node(cup , cur.B, cur, True)\n",
    "\n",
    "            cur.children.extend((left, right))\n",
    "            left.next_nodes.add(right)\n",
    "            right.next_nodes.update(cur.next_nodes)\n",
    "\n",
    "            stack.append((right, new_anc))\n",
    "            stack.append((left , new_anc))\n",
    "\n",
    "    # ── FINAL PASS – propagate via right-descendant rule  ─────────────\n",
    "    for p, q in duplicates:                         # p = leaf, q = ancestor\n",
    "        for r in nodes:\n",
    "            if is_right_desc(q, r) and r is not p:  # ▼ criterion\n",
    "                r.next_nodes.update(p.next_nodes)\n",
    "\n",
    "    return root, nodes, interfaces\n",
    "\n",
    "#print tree in ascii\n",
    "def print_tree(node: TreeNode, level=0, seen=None):\n",
    "    if seen is None: seen = set()\n",
    "    indent = \"  \" * level\n",
    "    tag = \" ↩\" if node.id in seen else \"\"\n",
    "    print(f\"{indent}{node.label()}  (id={node.id}){tag}\")\n",
    "    if node.back_edge:\n",
    "        print(f\"{indent}  ε-back → {node.back_edge.label()}[#${node.back_edge.id}]\")\n",
    "    if node.next_nodes:\n",
    "        nxt = \", \".join(f\"{n.label()}[#${n.id}]\" for n in node.next_nodes)\n",
    "        print(f\"{indent}  next → {nxt}\")\n",
    "    if node.id in seen:\n",
    "        return\n",
    "    seen.add(node.id)\n",
    "    for ch in node.children:\n",
    "        print_tree(ch, level+1, seen)\n",
    "        \n",
    "def show_tree_graph(\n",
    "    root: TreeNode,\n",
    "    show_next: bool = True,\n",
    "    show_back: bool = True,\n",
    "    engine: str = \"dot\",\n",
    "    rankdir: str = \"TB\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Render the parsing tree with Graphviz.\n",
    "    All nodes that have the same *tree depth* (distance through child edges\n",
    "    from the root) are forced into the same rank, so they appear at exactly\n",
    "    the same vertical position (rankdir='TB') or horizontal position\n",
    "    (rankdir='LR').\n",
    "    \"\"\"\n",
    "    import graphviz\n",
    "\n",
    "    dot = graphviz.Digraph(engine=engine)\n",
    "    dot.attr(rankdir=rankdir, nodesep=\"0.35\", ranksep=\"0.30\")\n",
    "    dot.attr(\"node\", shape=\"box\", fontname=\"monospace\", fontsize=\"10\")\n",
    "\n",
    "    # ── 1.  Add nodes + edges  ─────────────────────────────────────────\n",
    "    queue = [root]\n",
    "    seen = set()\n",
    "    while queue:\n",
    "        n = queue.pop(0)\n",
    "        if n.id in seen:\n",
    "            continue\n",
    "        seen.add(n.id)\n",
    "\n",
    "        # box label\n",
    "        dot.node(f\"n{n.id}\", n.label())\n",
    "\n",
    "        # child edges (solid black)\n",
    "        for ch in n.children:\n",
    "            dot.edge(f\"n{n.id}\", f\"n{ch.id}\")\n",
    "            queue.append(ch)\n",
    "\n",
    "        # next-relation (dashed blue)\n",
    "        if show_next:\n",
    "            for nxt in n.next_nodes:\n",
    "                dot.edge(f\"n{n.id}\", f\"n{nxt.id}\",\n",
    "                         style=\"dashed\", color=\"blue\", arrowhead=\"vee\")\n",
    "\n",
    "        # ε-back (dotted red)\n",
    "        if show_back and n.back_edge:\n",
    "            dot.edge(f\"n{n.id}\", f\"n{n.back_edge.id}\",\n",
    "                     style=\"dotted\", color=\"red\", arrowhead=\"vee\")\n",
    "\n",
    "    # ── 2.  Compute depth per node (children only)  ────────────────────\n",
    "    depth: dict[int, int] = {}\n",
    "    from collections import deque\n",
    "    dq = deque([(root, 0)])\n",
    "    while dq:\n",
    "        node, d = dq.popleft()\n",
    "        if node.id in depth:\n",
    "            continue\n",
    "        depth[node.id] = d\n",
    "        for ch in node.children:\n",
    "            dq.append((ch, d + 1))\n",
    "\n",
    "    # ── 3.  Force rank = same for every depth  ────────────────────────\n",
    "    max_depth = max(depth.values())\n",
    "    for d in range(max_depth + 1):\n",
    "        same_rank_nodes = [f\"n{nid}\" for nid, dep in depth.items() if dep == d]\n",
    "        if len(same_rank_nodes) > 1:                  # no need for singletons\n",
    "            with dot.subgraph() as sg:\n",
    "                sg.attr(rank=\"same\")\n",
    "                for name in same_rank_nodes:\n",
    "                    sg.node(name)\n",
    "\n",
    "    return dot        # displays inline in Jupyter / VS Code notebooks           # in Jupyter this auto-renders; otherwise use dot.view()        \n",
    "        \n",
    "def process_grammar(G: Grammar, s1: str, s2: str):\n",
    "    root, nodes, I_basic = build_tree(G, s1,s2)\n",
    "    print(f\"Parsing tree for {G.name} with s1='{s1}', s2='{s2}':\")\n",
    "    print_tree(root)                 # your ASCII printer\n",
    "    print(f\"{len(nodes)} total nodes\")\n",
    "    #print all non-empty interface, without frozenset\n",
    "    for (A, B), I in I_basic.items():\n",
    "        if I:  # non-empty interface\n",
    "            print(f\"I({set(A)}, {set(B)}) = {I}\")\n",
    "    show_tree_graph(root, show_next=True, show_back=True).view(f\"{G.name}_tree\")  # render the tree\n",
    "    print(\"\\n\" + \"=\"*40 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "fa505a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Example G1\n",
    "# process_grammar(G1, 'a', 'b')\n",
    "# #Example G2\n",
    "# process_grammar(G2, 'a', 'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "314ab160",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from automata.fa.nfa import NFA\n",
    "from typing import Dict, Tuple, Set, FrozenSet\n",
    "\n",
    "EPS = \"\"\n",
    "\n",
    "\n",
    "\n",
    "def accept_name(B: FrozenSet[str]) -> str:\n",
    "    return \"ACC_\" + (\"_\".join(sorted(B)) if B else \"ε\")\n",
    "\n",
    "\n",
    "def X_s(C: Set[str], G: Grammar) -> Set[str]:\n",
    "    up = set()\n",
    "    for a in C:\n",
    "        if a in G.Sigma_d:\n",
    "            up |= upward_closure(a, G)\n",
    "    return {EPS} | (C - up)\n",
    "\n",
    "\n",
    "from itertools import count\n",
    "\n",
    "def build_enfa_from_tree(\n",
    "    G: Grammar,\n",
    "    root: TreeNode,\n",
    "    nodes: list[TreeNode],\n",
    "    interfaces: dict[tuple[FrozenSet[str], FrozenSet[str]], set[str]],\n",
    ") -> NFA:\n",
    "    # pretty \"(a,b)\" part\n",
    "    def pretty(A, B):\n",
    "        a = \",\".join(sorted(A)) or \"∅\"\n",
    "        b = \",\".join(sorted(B)) or \"∅\"\n",
    "        return f\"({a},{b})\"\n",
    "\n",
    "    # assign ONE descriptive name per node\n",
    "    for n in nodes:\n",
    "        n.nfa_name = f\"{pretty(n.A, n.B)}#{n.id}\"\n",
    "\n",
    "    # acceptor names  ACC_b_c  or ACC_ε\n",
    "    acc_for: dict[FrozenSet[str], str] = {}\n",
    "    def acc(B):\n",
    "        if B not in acc_for:\n",
    "            acc_for[B] = \"ACC_\" + (\"_\".join(sorted(B)) if B else \"ε\")\n",
    "        return acc_for[B]\n",
    "\n",
    "    tr: dict[str, dict[str, set[str]]] = {}\n",
    "\n",
    "    for n in nodes:\n",
    "        sid = n.nfa_name\n",
    "        tr.setdefault(sid, {})\n",
    "\n",
    "        # loops on A\n",
    "        for a in n.A:\n",
    "            tr[sid].setdefault(a, set()).add(sid)\n",
    "\n",
    "        # ε → left child\n",
    "        for ch in n.children:\n",
    "            if not ch.is_right:\n",
    "                tr[sid].setdefault(\"\", set()).add(ch.nfa_name)\n",
    "\n",
    "        # ε back-edge\n",
    "        if n.back_edge:\n",
    "            tr[sid].setdefault(\"\", set()).add(n.back_edge.nfa_name)\n",
    "\n",
    "        # next + accept edges\n",
    "        C_star = X_s(interfaces[(n.A, n.B)], G)\n",
    "        sink    = acc(n.B)\n",
    "        for sym in C_star:\n",
    "            for nxt in n.next_nodes:\n",
    "                tr[sid].setdefault(sym, set()).add(nxt.nfa_name)\n",
    "            tr[sid].setdefault(sym, set()).add(sink)\n",
    "\n",
    "        # sink loops on B\n",
    "        tr.setdefault(sink, {})\n",
    "        for b in n.B:\n",
    "            tr[sink].setdefault(b, set()).add(sink)\n",
    "\n",
    "    return NFA(\n",
    "        states=set(tr),\n",
    "        input_symbols=set(G.alphabet),\n",
    "        transitions=tr,\n",
    "        initial_state=root.nfa_name,\n",
    "        final_states=set(acc_for.values()),\n",
    "    )\n",
    "\n",
    "\n",
    "from graphviz import Digraph, Source\n",
    "\n",
    "def draw_nfa(nfa, eps_symbol=\"ε\", rankdir=\"LR\"):\n",
    "    \"\"\"\n",
    "    Render an automata-lib NFA *without* pygraphviz / coloraide.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    nfa        – automata.fa.nfa.NFA instance\n",
    "    eps_symbol – label to print for epsilon (default 'ε')\n",
    "    rankdir    – 'LR' for left-right, 'TB' for top-down\n",
    "    \"\"\"\n",
    "    dot = Digraph()\n",
    "    dot.attr(rankdir=rankdir, nodesep=\"0.35\", ranksep=\"0.25\")\n",
    "    dot.attr(\"node\", shape=\"circle\", fontname=\"monospace\", fontsize=\"10\")\n",
    "\n",
    "    # invisible start arrow\n",
    "    dot.node(\"\", shape=\"plaintext\", label=\"\")\n",
    "    dot.edge(\"\", nfa.initial_state)\n",
    "\n",
    "    # render states\n",
    "    for state in nfa.states:\n",
    "        shape = \"doublecircle\" if state in nfa.final_states else \"circle\"\n",
    "        dot.node(str(state), shape=shape)\n",
    "\n",
    "    # transitions\n",
    "    for src, symdict in nfa.transitions.items():\n",
    "        for sym, dsts in symdict.items():\n",
    "            label = eps_symbol if sym == \"\" else sym\n",
    "            for dst in dsts:\n",
    "                dot.edge(str(src), str(dst), label=label)\n",
    "\n",
    "    return Source(dot.source)   # displays inline in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "62ae9b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"240pt\" height=\"117pt\"\n",
       " viewBox=\"0.00 0.00 239.80 117.46\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 113.46)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-113.46 235.8,-113.46 235.8,4 -4,4\"/>\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title></title>\n",
       "</g>\n",
       "<!-- (a,b)#0 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>(a,b)#0</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"107.73\" cy=\"-34.73\" rx=\"34.96\" ry=\"34.96\"/>\n",
       "<text text-anchor=\"middle\" x=\"107.73\" y=\"-32.23\" font-family=\"monospace\" font-size=\"10.00\">(a,b)#0</text>\n",
       "</g>\n",
       "<!-- &#45;&gt;(a,b)#0 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>&#45;&gt;(a,b)#0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M54.22,-34.73C57.03,-34.73 59.94,-34.73 62.88,-34.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"62.93,-38.23 72.93,-34.73 62.93,-31.23 62.93,-38.23\"/>\n",
       "</g>\n",
       "<!-- (a,b)#0&#45;&gt;(a,b)#0 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>(a,b)#0&#45;&gt;(a,b)#0</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M99.55,-68.5C98.99,-82.55 101.72,-94.46 107.73,-94.46 112.2,-94.46 114.85,-87.9 115.69,-78.78\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"119.19,-78.58 115.91,-68.5 112.2,-78.43 119.19,-78.58\"/>\n",
       "<text text-anchor=\"middle\" x=\"107.73\" y=\"-98.26\" font-family=\"Times,serif\" font-size=\"14.00\">a</text>\n",
       "</g>\n",
       "<!-- ACC_b -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>ACC_b</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"200.13\" cy=\"-34.73\" rx=\"27.81\" ry=\"27.81\"/>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"200.13\" cy=\"-34.73\" rx=\"31.84\" ry=\"31.84\"/>\n",
       "<text text-anchor=\"middle\" x=\"200.13\" y=\"-32.23\" font-family=\"monospace\" font-size=\"10.00\">ACC_b</text>\n",
       "</g>\n",
       "<!-- (a,b)#0&#45;&gt;ACC_b -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>(a,b)#0&#45;&gt;ACC_b</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M142.65,-34.73C147.65,-34.73 152.84,-34.73 157.96,-34.73\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"158.3,-38.23 168.3,-34.73 158.3,-31.23 158.3,-38.23\"/>\n",
       "<text text-anchor=\"middle\" x=\"155.46\" y=\"-38.53\" font-family=\"Times,serif\" font-size=\"14.00\">ε</text>\n",
       "</g>\n",
       "<!-- ACC_b&#45;&gt;ACC_b -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>ACC_b&#45;&gt;ACC_b</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M192.01,-65.62C191.23,-79.45 193.94,-91.4 200.13,-91.4 204.72,-91.4 207.4,-84.81 208.15,-75.77\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"211.66,-75.66 208.25,-65.62 204.66,-75.59 211.66,-75.66\"/>\n",
       "<text text-anchor=\"middle\" x=\"200.13\" y=\"-95.2\" font-family=\"Times,serif\" font-size=\"14.00\">b</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x7f1667013e20>"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root, nodes, interfaces = build_tree(G3, 'a', 'b')\n",
    "nfa = build_enfa_from_tree(G3, root, nodes, interfaces)\n",
    "#print(nfa.accepts_input('abcbcbcccb'))  # quick membership test\n",
    "draw_nfa(nfa)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d498144",
   "metadata": {},
   "source": [
    "Loop that grows the interface until saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "7d4df5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque\n",
    "from copy import deepcopy\n",
    "from typing import Dict, Tuple, Set, FrozenSet\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Helper: pretty \"(a,b)\"  and counter-based unique names\n",
    "# --------------------------------------------------------------\n",
    "from collections import defaultdict\n",
    "\n",
    "def pretty_AB(A: FrozenSet[str], B: FrozenSet[str]) -> str:\n",
    "    a = \",\".join(sorted(A)) or \"∅\"\n",
    "    b = \",\".join(sorted(B)) or \"∅\"\n",
    "    return f\"({a},{b})\"\n",
    "\n",
    "# per-label counters\n",
    "_label_counter: defaultdict[Tuple[FrozenSet, FrozenSet], int] = defaultdict(int)\n",
    "\n",
    "def unique_state_name(node: TreeNode) -> str:\n",
    "    lbl = (node.A, node.B)\n",
    "    _label_counter[lbl] += 1\n",
    "    k = _label_counter[lbl]\n",
    "    return f\"{pretty_AB(node.A, node.B)}_{k}\"\n",
    "\n",
    "# ───────────────────────── helper to scan one NFA ───────────────────────\n",
    "def scan_nfa_for_new_interfaces(\n",
    "    nfa: NFA,\n",
    "    G: Grammar,\n",
    "    nodes: list[TreeNode],\n",
    "    interfaces: dict[tuple[FrozenSet[str], FrozenSet[str]], set[str]],\n",
    "):\n",
    "    add = defaultdict(set)\n",
    "\n",
    "    label_of = {n.nfa_name: (n.A, n.B) for n in nodes}\n",
    "\n",
    "    # ε-closures ---------------------------------------------------------\n",
    "    eps = {}\n",
    "    for s in nfa.states:\n",
    "        cl, dq = {s}, deque([s])\n",
    "        while dq:\n",
    "            u = dq.popleft()\n",
    "            for v in nfa.transitions[u].get(\"\", []):\n",
    "                if v not in cl:\n",
    "                    cl.add(v); dq.append(v)\n",
    "        eps[s] = cl\n",
    "\n",
    "    step = lambda sym, S: {v2\n",
    "        for q in S\n",
    "        for v1 in nfa.transitions[q].get(sym, [])\n",
    "        for v2 in eps[v1]}\n",
    "\n",
    "    # rules 1 & 2 --------------------------------------------------------\n",
    "    for rule in G.binary_rules():\n",
    "        x, y = rule.lhs\n",
    "        z, = rule.rhs\n",
    "\n",
    "        for p in label_of:\n",
    "            A, _ = label_of[p]\n",
    "\n",
    "            Sx = step(x, eps[p])\n",
    "            if not Sx: continue\n",
    "\n",
    "            # rule 2\n",
    "            for s in Sx:\n",
    "                lbl_s = label_of.get(s)\n",
    "                if lbl_s:\n",
    "                    C, D = lbl_s\n",
    "                    if y in interfaces.get(lbl_s, set()).union(D) and A!=D:\n",
    "                        if z in A or z in D:            # <-- new guard\n",
    "                             continue\n",
    "                        add[(A, D)].add(z)\n",
    "\n",
    "            # rule 1\n",
    "            Sy = step(y, Sx)\n",
    "            for t in Sy:\n",
    "                lbl_t = label_of.get(t)           # skip acceptors\n",
    "                if lbl_t:\n",
    "                    C, _ = lbl_t\n",
    "                    if A != C:\n",
    "                        if z in A or z in C:           \n",
    "                            continue\n",
    "                        add[(A, C)].add(z)\n",
    "\n",
    "    # rule 3 -------------------------------------------------------------\n",
    "    for p in label_of:\n",
    "        A, _ = label_of[p]\n",
    "        for z in G.alphabet:\n",
    "            Sz = step(z, eps[p])\n",
    "            for t in Sz:\n",
    "                lbl_t = label_of.get(t)\n",
    "                if lbl_t:\n",
    "                    C, D = lbl_t\n",
    "                    if z not in A.union(C) and A != C:\n",
    "                        add[(A, C)].add(z)\n",
    "\n",
    "    # discard duplicates\n",
    "    for k in list(add):\n",
    "        add[k] -= interfaces.get(k, set())\n",
    "        if not add[k]:\n",
    "            del add[k]\n",
    "    return add\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "#  Driver : iterate until no interface grows\n",
    "# ---------------------------------------------------------------\n",
    "def saturate_interfaces(G: Grammar, s1: str, s2: str, verbose=False, max_iter=100):\n",
    "\n",
    "    interfaces: dict[Tuple[FrozenSet, FrozenSet], set[str]] = {}\n",
    "\n",
    "    for it in range(1, max_iter + 1):\n",
    "        root, nodes, interfaces = build_tree(G, s1, s2, interfaces)\n",
    "\n",
    "        nfa   = build_enfa_from_tree(G, root, nodes, interfaces)\n",
    "        delta = scan_nfa_for_new_interfaces(nfa, G, nodes, interfaces)\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Iter {it}: +{sum(map(len,delta.values()))} letters, |I|={len(interfaces)}\")\n",
    "        if not delta:\n",
    "            return interfaces, root, nodes, nfa\n",
    "\n",
    "        # merge delta before next loop\n",
    "        for k, v in delta.items():\n",
    "            interfaces.setdefault(k, set()).update(v)\n",
    "\n",
    "    raise RuntimeError(\"No convergence in max_iter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "40b8c262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1: +11 letters, |I|=6\n",
      "Iter 2: +0 letters, |I|=7\n",
      "Final interfaces for G3 with s1='0', s2='a':\n",
      "I({'a'}, {'b'}) = {'d', 'c', 'f', 'g', 'e'}\n",
      "I({'a'}, {'c'}) = {'e'}\n",
      "I({'c'}, {'b'}) = {'d', 'a', 'f', 'g', 'e'}\n",
      "I({'a'}, {'g'}) = {'c', 'e'}\n",
      "I({'c'}, {'a'}) = {'e'}\n",
      "I({'c'}, {'g'}) = {'a', 'e'}\n"
     ]
    }
   ],
   "source": [
    "#run the loop\n",
    "interfaces, root, nodes, nfa = saturate_interfaces(G1, 'a', 'b', verbose=True)\n",
    "#final automaton\n",
    "#print(nfa.accepts_input('01←ab'))  # quick membership test\n",
    "#show the final automaton\n",
    "#draw_nfa(nfa, eps_symbol=EPS, rankdir=\"LR\").view(\"final_nfa\")\n",
    "print(f\"Final interfaces for {G3.name} with s1='0', s2='a':\")\n",
    "# print all non-empty interface, without frozenset\n",
    "for (A, B), I in interfaces.items():\n",
    "    if I:  # non-empty interface\n",
    "        print(f\"I({set(A)}, {set(B)}) = {I}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "83a5dca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membership tests:\n",
      "  ab              : True\n",
      "  acb             : True\n",
      "  abed            : False\n",
      "  abcb            : False\n",
      "  aaaf            : True\n"
     ]
    }
   ],
   "source": [
    "#test membership\n",
    "print(\"Membership tests:\")\n",
    "test_strings = [\n",
    "    'ab',\n",
    "    'acb',\n",
    "    'abed',\n",
    "    'abcb',\n",
    "    'aaaf'\n",
    "    \n",
    "]\n",
    "for test in test_strings:\n",
    "    result = nfa.accepts_input(test)\n",
    "    print(f\"  {test:15} : {result}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
